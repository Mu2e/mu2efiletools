#!/usr/bin/perl -w
#
# Checks output of "production" grid jobs (run with mu2eprodsys) and
# moves them into "good" or other subdirectories, preserving the
# directory structure a mu2eprodsys cluster outputs.
# If a good job happens to have a "temporary" directory name
# used by the outstage  ifdh, the suffix is stripped.
#
# A.Gaponenko, 2015
#

use strict;
use English '-no_match_vars';
use File::Basename;
use File::Path;
use File::stat;
use Cwd 'abs_path';
use Getopt::Long;
use Digest;
use JSON;
use HTTP::Status qw(:constants);
use Data::Dumper;
use Mu2eFilename;

use lib dirname($0);
use Mu2eSWI;
use Mu2eClusterDir;

# the fields correspond to metadata parameters of Mu2e job tracking entries in SAM.
use Class::Struct Mu2eJobStats => [ cpu=>'$', maxres=>'$', node=>'$', site=>'$', disk=>'$' ];

use Class::Struct Mu2eLogFileInfo => [
    manifest_selfhash=>'$',
    logfilehash=>'$',
    workerFileSize=>'%',
    workerFileDigest=>'%',
    payload_started=>'$',
    payload_ok=>'$',
    parent_fcl=>'$',
    mu2ejobname=>'$',
    mu2ejobindex=>'$',
    job_stats=>'Mu2eJobStats',
    ];

my $timecut = 2*3600; # in seconds
my $verbosity=1;
my $dryrun=0;
my $nosam=0;
my $sw = Mu2eSWI->new;
my %opt = ('verify-data'=>1,
           'timecut'=>\$timecut,
           verbosity=>\$verbosity,
           'nosam' => \$nosam,
           'dry-run'=>\$dryrun,
           help=>0,
           oldhack=>0,
           %{$sw->optDefaults},
    );

# constant strings used as keys in the jobStats hash
use constant GOOD => '0good'; # make it sort first in the summary output.  That string is not exposed.
# the rest of the strings are used as directory names for failed jobs
use constant NOLOG => 'nolog';
use constant LOGCHECK => 'logcheck';
use constant EXITSTAT => 'exitstat';
use constant DATASIZE => 'datasize';
use constant METAPAIRED => 'metapaired';
use constant DATACHECK => 'datacheck';
use constant GRIDDUP => 'dup_grid';
use constant RESUBDUP => 'dup_resub';
my %jobStats;

# A more readable description for the summary output
my %errorCodes = (
    GOOD() => 'Good',
    NOLOG() => 'no unique log file',
    LOGCHECK() => 'corrupted log file',
    EXITSTAT() => 'bad exit status',
    DATASIZE() => 'wrong data or json file size',
    METAPAIRED() => 'a non-paired content or json file',
    DATACHECK() => 'corrupted data file',
    GRIDDUP() => 'duplicate (grid glitch)',
    RESUBDUP() => 'duplicate (multiple submissions)',
    );

# some execution statistics
my $totalServerTime = 0;
my $currentJobNumber = 0;

#================================================================
sub dsttop($) {
    my ($clusterdir) = @_;
    my $res = $opt{'dsttop'};

    if(not defined $res) {

        if($clusterdir =~ m'^(.*)/workflow/([^/]+)/outstage/([^/]+)$') {
            my ($prefix, $project, $cluster) = ($1, $2, $3);
            $res = "$prefix/workflow/$project";
        }
        else {
            die "No heuristic to determine --dsttop for $clusterdir\nPlease use the --dsttop command line option.\n";
        }
    }

    return $res;
}

#================================================================
# extract the "cluster/spreader/process" part from a potentially
# longer jobname string
sub reljobdir($) {
    my ($indir) = @_;

    die "Error: reljobdir() expects at least two '/' symbols on input.  Got: '$indir'\n"
        unless $indir =~ m|([^/]+/[^/]+/[^/]+)$|;
    my $res = $1;

    return $res;
}

#================================================================
sub getLogFileName($) {
    my ($jobdir) = @_;
    my @list = glob "$jobdir/*.log";
    return ($#list == 0) ? $list[0] : "";
}

#================================================================
sub verifyDigest($$) {
    my ($fn, $expectedDigest) = @_;
    my $dig = Digest->new('SHA-256');

    my $ret = 0;

    # A stat() has just succeeded on the file.  It it is not readable
    # we break here instead of classifying the job as a failure.  Such
    # misclassification was seen in --dry-run tests because of wrong
    # permissions after coping files from another system.

    open(my $fh, '<', $fn) or die "Error opening file '$fn': $!\n";

    $dig->addfile($fh);
    if($dig->hexdigest eq $expectedDigest) {
        $ret = 1;
    }

    return $ret;
}

#================================================================
sub processLogFile($) {
    my ($logFileName) = @_;

    my $payload_started = 0;
    my $mu2egrid_status_ok = 0;
    my $art_status_ok = 0;
    my $manifest_selfhash='';

    my $cobalt_manager = 0; # COBALT batch system does not provide a site name, we'll need to guess.
    my $maybe_theta = 0;  # Theta is a site that uses the COBALT system.

    # Note: dynamic determination of hash alg would need two passes over $logFileName
    # We've always been using sha256sum on worker nodes
    my $loghash = Digest->new('SHA-256');

    my %workerFileSize;
    my %workerFileDigest;

    my $parent_fcl;
    my ($mu2ejobname, $mu2ejobindex);
    my $job_stats = Mu2eJobStats->new;

    my $parentRE =  $opt{'oldhack'} ?
        '^origFCL *= *(.*)$' :
        '^mu2eprodsys *origFCL *= *(.*)$';

    if(open(my $logfh, $logFileName)) {

        my $manifest_started = 0;

        while(my $line = <$logfh>) {

            if($line =~ m/^Running the command:.* mu2e /) {
                $payload_started = 1;
            }

            if($line =~ m/$parentRE/) {
                $parent_fcl = $1;
            }

            # FIXME: hack using jobdef instead of jobname
            if($line =~ m/^mu2ejobsub +jobdef *= *(.*)$/) {
                $mu2ejobname = basename($1);
            }
            if($line =~ m/^mu2ejobsub +jobname *= *(.*)$/) {
                $mu2ejobname = $1;
            }

            if($line =~ m/^mu2ejobsub +jobindex *= *(.*)$/) {
                $mu2ejobindex = $1;
            }

            if($line =~ m/^mu2egrid exit status 0 ?.*$/) {
                $mu2egrid_status_ok = 1;
            }

            if($line =~ m/^Art has completed and will exit with status 0\.$/) {
                $art_status_ok = 1;
            }

            if($line =~ m/^([\d\.]+)user *([\d\.]+)system .*elapsed.* (\d+)maxresident/) {
                $job_stats->cpu($1 + $2);
                $job_stats->maxres($3);
            }

            if($line =~ m/^(mu2eprodsys|mu2ejobsub|mu2egrid)\s*diskUse\s*=\s*(\d+)\s/) {
                $job_stats->disk($2);
            }

            if($line =~ m/^Starting *on *host *Linux *([^\s]+)\s/) {
                $job_stats->node($1);
            }

            if($line =~ m/^GLIDEIN_Site *= *(.*)$/) {
                $job_stats->site($1);
            }

            if($line =~ m/^SLURM_CLUSTER_NAME *= *(.*)$/) {
                $job_stats->site($1);
            }

            if($line =~ m/^COBALT_QUEUE/) {
                $cobalt_manager = 1;
            }

            if($line =~ m/^HOST=theta/i) {
                $maybe_theta = 1;
            }

            if($manifest_started) {
                if($line =~ m/^#/) {
                    # extract file size information from the "ls -l" output
                    my @fields = split(/\s+/, $line);
                    if($#fields == 9) {
                        my $filename = $fields[9];
                        my $filesize = $fields[5];
                        $workerFileSize{$filename} = $filesize;
                    }
                }
                else {
                    # manifest lines not starting with '#' must list dataset files
                    if($line =~ m/^([[:xdigit:]]+)\s+([^\s]+)$/) {
                        my $digest = $1;
                        my $filename = $2;
                        $workerFileDigest{$filename} = $digest;
                    }
                    else {
                        print "\tError parsing manifest line \"$line\" in $logFileName\n" if $verbosity;
                        # returning an uninitialized object will mark this job as failed
                        return Mu2eLogFileInfo->new;
                    }
                }
            } # manifest_started

            if($line =~ m/^# mu2egrid manifest *$/) {
                $manifest_started = 1;
            }

            if($line =~ m/^# mu2egrid manifest selfcheck: ([[:xdigit:]]+) *- *$/) {
                $manifest_selfhash = $1;
            }
            else {
                $loghash->add($line);
            }

        }

        if($payload_started and not defined $parent_fcl  and not defined $mu2ejobname) {
            die "Did not find information about parent fcl or jobname in $logFileName\n";
        }

        my $payload_ok = $mu2egrid_status_ok && $art_status_ok;

        if(!defined($job_stats->site)) {
            if($cobalt_manager) {
                if($maybe_theta) {
                    $job_stats->site('theta');
                }
            }
        }

        return Mu2eLogFileInfo->new(manifest_selfhash=>$manifest_selfhash,
                                    logfilehash=>$loghash->hexdigest,
                                    workerFileSize=>\%workerFileSize,
                                    workerFileDigest=>\%workerFileDigest,
                                    payload_started=>$payload_started,
                                    payload_ok=>$payload_ok,
                                    parent_fcl=>$parent_fcl,
                                    mu2ejobname=>$mu2ejobname,
                                    mu2ejobindex=>$mu2ejobindex,
                                    job_stats=>$job_stats,
            );
    }
    else {
        print "\tError opening log file $logFileName\n" if $verbosity;
    }

    # returning an uninitialized object will mark this job as failed
    return Mu2eLogFileInfo->new;
}

#================================================================
sub maybe_rename($$) {
    my ($src, $dst) = @_;
    print "\t", ($dryrun ? "Would move":"Moving" ) ,": $src ====> $dst\n" if $verbosity > 1;
    if(!$dryrun) {
        rename($src, $dst) or die "Error in rename($src, $dst): $!  on " . localtime() . "\n";
    }
}

#================================================================
sub moveFailedJob($$$) {
    (my $jobdir, my $dsttop, my $reason) = @_;

    ++$jobStats{$reason};

    my $subdir = dirname("$dsttop/failed/$reason/" . reljobdir($jobdir));
    if(!-d $subdir and not $dryrun) {
        File::Path::make_path($subdir); # don't die: parallel uploads create a race condition
        # if make_path() failed because of a race, the directory must exist
        -d $subdir or die "Error creating directory $subdir: $! on ". localtime() ."\n";
    }

    my $dstname = $subdir .'/'. basename($jobdir);
    my $done = 0;
    my $numtries = 0;
    do {
        eval { maybe_rename($jobdir, $dstname); };
        if($@) {
            die $@ if(++$numtries > 99);
            $dstname = $subdir .'/'. basename($jobdir) . '.fail' . sprintf('%02d', $numtries);
        }
        else {
            $done = 1;
        }
    } until $done;
}

#================================================================
# Grid jobs copy outputs into a temporary directory named like
# 00826.0144a733.  Normally such dirs are renamed to keep just the
# first part, "00826".  Sometimes the renaming fails, but otherwise
# the job is good.  Strip the tmp suffux to detect in-cluster
# duplicates.

sub stripTmpSuffix($) {
    my ($orig) = @_;

    my $dir = dirname($orig);
    my $base = basename($orig);

    $base =~ s/\.[[:xdigit:]]+$//;

    die "Unexpected job directory name: $base. Expect 5 decimal digits after stripping the tmp suffix.\n"
        unless $base =~ /^\d{5}$/;

    return "$dir/$base";
}

#================================================================
# Move job dir to the dst area
sub moveGoodJob($$) {
    (my $jobdir, my $dsttop) = @_;
    my $dstdir = stripTmpSuffix("$dsttop/good/" . reljobdir($jobdir));
    if(!$dryrun) {
        my $gooddir = dirname($dstdir);
        if(not -d $gooddir) {
            File::Path::make_path($gooddir)
                or die "Error creating directory $gooddir: $! on ".localtime()."\n";
        }
    }
    maybe_rename($jobdir, $dstdir);
}

#================================================================
sub isGridDup($$) {
    my ($jobdir, $dsttop) = @_;

    my $dstname = stripTmpSuffix("$dsttop/good/" . reljobdir($jobdir));

    my $res = (-e $dstname) ? 1 : 0;
    if($verbosity > 1) {
        print "\tisGridDup($jobdir) = $res\n";
    }
    return $res;
}

#================================================================
sub isGlobalDup($$$) {
    my ($sw, $logFileName, $loginfo) = @_;

    my $lf = Mu2eFilename->parse(basename($logFileName));

    # a unique string to identify this job for duplicate detection
    # and the corresponding "dataset"
    my ($jtfn, $jtds);
    my $parentfn; # input fcl file for mu2eprodsys case
    if($loginfo->parent_fcl) { # handle mu2eprodsys outputs

        $parentfn = basename($loginfo->parent_fcl);

        my $parentds = Mu2eFilename->parse($parentfn)->dataset->dsname;

        $jtfn = join('.', 'job' , $lf->owner, $lf->configuration, $parentfn);
        $jtds = join('.', 'job' , $lf->owner, $lf->configuration, $parentds);

    }
    elsif($loginfo->mu2ejobname) {
        # for mu2ejobsub it is sufficient to use the log file name, derived from jobname and index
        $jtfn = 'job.' . basename($logFileName);
        $jtds = 'job.' . Mu2eFilename->parse(basename($logFileName))->dataset->dsname;

        # $parentfn = $loginfo->mu2ejobname; # this requires that the jobdef file is registered in sam
    }
    else {
        die "isGlobalDup(): got loginfo with neither parent_fcl nor mu2ejobname defined";
    }

    my $st = $loginfo->job_stats;

    # Make sure all fields in $st are defined.  Do not try to send
    # empty strings to SAM DB.
    my $cnt=0;
    foreach my $i (@{$st}) {
        defined $i or die "Error; Mu2eJobStats field $cnt not defined for $logFileName\n";
        ++$cnt;
    }


    my $jsstruct = { data_tier => 'job',
                     file_name => $jtfn,
                     file_size => 0,
                     file_type => 'other',

                     'dh.configuration' => $lf->configuration,
                     'dh.owner' => $lf->owner,
                     'dh.sequencer' => $lf->sequencer,
                     'dh.dataset' => $jtds,

                     # Use this a (statistically) unique identifier
                     # of the job.   Needed to figure out which of several
                     # potential grid re-runs this record corresponds to.
                     'dh.sha256' => $loginfo->manifest_selfhash,

                     'job.cpu' => int(0.5+$st->cpu),
                     'job.maxres' => $st->maxres,
                     'job.disk' => $st->disk,
                     'job.node' => $st->node,
                     'job.site' => $st->site,
    };

    if(defined $parentfn) {
        $jsstruct->{'parents'} = [ $parentfn ];
    }

    my $json_text = to_json($jsstruct);

    print "\t", ($dryrun ? "Would" : "About to"), " post json = $json_text\n" if $verbosity > 1;

    my $duplicate = !$dryrun;

    if(!$dryrun) {
        my $res = $sw->declareFile($json_text,
                                   { serverDeclareTime=>\$totalServerTime,
                                     verbosity=>$verbosity,
                                     allowedFailCodes => [ HTTP_CONFLICT ]
                                   });

        if($res->is_success) {
            $duplicate = 0;
        }
        else {
            # Does the SAM record correspond to some other job
            # instance, or was it created for our instance but a
            # previous mu2eClusterCheckAndMove process died before
            # completing the directory move?
            my $samsha = $sw->getSamSha($jtfn);
            if($samsha eq $loginfo->manifest_selfhash) {
                print "Duplicate check: existing SAM record corresponds to the current job.  Accepting $logFileName\n"
                    if $verbosity > 0;

                $duplicate = 0;
            }
        }
    }

    return $duplicate;
}

#================================================================
sub processJobDir($$$) {
    my ($sw, $jobdir, $dsttop) = @_;
    print "Processing $jobdir\n" if $verbosity > 1;

    my $failed = 1;
    my @filesToUpload;

  CHECK: # put all the checks into a fake loop
    # then use loop control "last" to avoid mutiple nested "if"-s.
    while(1) {

        my $logFileName = getLogFileName($jobdir);
        if(!$logFileName) {
            print "\tNo unique log file for $jobdir\n" if $verbosity;
            moveFailedJob($jobdir, $dsttop, NOLOG());
            last CHECK;
        }

        my $loginfo = processLogFile($logFileName);

        if(not defined $loginfo->payload_ok) {
            moveFailedJob($jobdir, $dsttop, LOGCHECK());
            last CHECK;
        }

        if($loginfo->payload_started and !$loginfo->payload_ok) {
            print "\tJob did not run correctly in $jobdir\n" if $verbosity;
            moveFailedJob($jobdir, $dsttop, EXITSTAT());
            last CHECK;
        }

        if($loginfo->manifest_selfhash ne $loginfo->logfilehash) {
            print "\tLog file checksum mismatch for $jobdir\n" if $verbosity;
            moveFailedJob($jobdir, $dsttop, LOGCHECK());
            last CHECK;
        }

        # Look at the files listed in the manifest:
        my $jsonpattern = '\.json$';
        my @contentFiles = grep { ! /$jsonpattern/ } keys %{$loginfo->workerFileDigest};
        my @metaFiles = grep {  /$jsonpattern/ } keys %{$loginfo->workerFileDigest};

        # Verify integrity of files listed in the manifest:
        foreach my $fn (keys %{$loginfo->workerFileDigest}) {
            my $st = stat($jobdir.'/'. $fn);

            if(!$st or $st->size != $loginfo->workerFileSize($fn)) {
                print "\tError stat-ing file $jobdir/$fn\n" if $verbosity;
                moveFailedJob($jobdir, $dsttop, DATASIZE());
                last CHECK;
            }

            # .art files are normally uploaded and checked after the upload
            # so we don't do it here by default.  Json files are never
            # uploaded (and are small).   The checkAndMove step is a good
            # place to verify them.
            if($opt{'verify-data'} or $fn =~ /$jsonpattern/) {
                if(!verifyDigest($jobdir.'/'.$fn, $loginfo->workerFileDigest($fn))) {
                    print "\tDigest mismatch for $jobdir/$fn\n" if $verbosity;
                    moveFailedJob($jobdir, $dsttop, DATACHECK());
                    last CHECK;
                }
            }
        }

        #----------------
        # Detect duplicates.  First, check for processes that completed more than
        # once in the same cluster
        if(isGridDup($jobdir, $dsttop)) {
            print "\tDuplicated dir $jobdir, grid glitch\n" if $verbosity;
            moveFailedJob($jobdir, $dsttop, GRIDDUP());
            last CHECK;
        }

        #----------------
        # Now do the global check via the SAM database
        if(not $nosam) {
            if(isGlobalDup($sw, $logFileName, $loginfo)) {
                print "\tDuplicated dir $jobdir, multiple submissions\n" if $verbosity;
                moveFailedJob($jobdir, $dsttop, RESUBDUP());
                last CHECK;
            }
        }

        #----------------
        # All checks passed
        $failed = 0;
        ++$jobStats{GOOD()};
        moveGoodJob($jobdir, $dsttop);
        last CHECK;
    }

    print ++$currentJobNumber, "  ",
    ($failed ? "FAILED" : "OK"), ":\t$jobdir on ",scalar(localtime()),"\n" if $verbosity;
}

#================================================================
sub isTooRecent($) {
    my ($jobdir) = @_;

    # FIXME: also check time stamps of all the files, not just the dir?
    my $now = time();

    # It is OK for the stat() call here to fail: the NNNNN.xxxxx
    # directories get renamed by completing grid jobs, so there is a
    # race condition.  If the stat() fails just assume the candidate
    # dir is too fresh to be analyzed.

    my $too_recent = 1;
    if(my $st = stat($jobdir)) {
        $too_recent = (($now - $st->mtime) < $timecut);
    }

    return $too_recent;
}

#================================================================
# The order of args is fixed by Mu2eClusterDir::iterate
# and is different than in other funtions here.
sub iterateCallBack {
    my ($jobdir, $sw, $dsttop) = @_;

    if(isTooRecent($jobdir)) {
        print "Skipping $jobdir:  too recent\n"  if $verbosity > 1;
    }
    else {
        processJobDir($sw, $jobdir, $dsttop);
    }
}

#================================================================
sub usage() {
    my $self = basename($0);
    return <<EOF
Usage:
        $self [options] clusterdir1 [clusterdir2 ....]

This will check outputs of the given grid clusters in an outstage
area, and move individual job directories into a "good" subdirectory,
or one of subdirectories for failed jobs inside a destination area.
See the --dsttop option below.  The command can be run repeatedly on
the same cluster as more jobs complete.

The supported options are

    --[no]verify-data     Compute and check a SHA-256 digest of all files.
                          This is on by default.  If --noverify-data
                          is used, only json and log file checksums will
                          be verified.

    --timecut=<int>       Skip outputs that were modified more recently than the
                          given number of seconds - they may still be written by
                          a grid process.  The default --timecut is $timecut seconds.

    --dsttop=<directory>  Use the specified directory as the destination area.
                          Grid job directories will be moved into <dsttop>/good
                          or subdirs of <dsttop>/failed.
                          If the --dsttop option is not specified, a cluster from from
                          <prefix>/workflow/<wfproject>/outstage   will use
                          <prefix>/workflow/<wfproject>   as --dsttop.

    --oldhack             Since mu2egrid v3_01_01 job log files contain a
                          dedicated line to convey parent fcl info.
                          For older logs, origFCL info happens to be visible
                          in the environment dump.  This options tells
                          the script to get origFCL from the environment
                          printout.

EOF
. $sw->optDocString(' 'x4, ' 'x5) .
<<EOF

    --nosam               Do not connect to the SAM server.  This will
                          disable detection of duplicate jobs.  Also,
                          mu2eMissingJobs will not work for clusters
                          checked with --nosam.  This option is only
                          needed to support use cases when the parent
                          fcl dataset itself is not registered in SAM.

    --dry-run             Analyze jobdirs, but do not move the files.

    --verbosity=<int>     Verbosity level.  The default is 1.

    --help                Print this message.

The "faildir" directory should be on the same filesystem as the
jobdirs, so that failed job outputs can be moved (not copied) into it.
EOF
;
}

#================================================================
# Process command line opts.
GetOptions(\%opt,
    "dsttop=s",
    "verify-data!",
    "timecut=i",
    "verbosity=i",
    "nosam",
    "dry-run",
    "stdin",
    "help",
    "oldhack",
    @{$sw->optSpec},
    )
    or die "\nError processing command line options.\n";

if($opt{'help'}) {
    print usage();
    exit 0;
}

die "What job cluster(s) do you want to process? Try the --help option.\n" if ($#ARGV < 0);

if($nosam) {
    $sw = undef;
}
else {
    $sw->authConfig();
}

foreach my $in (@ARGV) {
    my $dir = abs_path($in);
    die "Error: can not determine abs_path for $in\n"
        unless $dir;

    my $dsttop = dsttop($dir);
    Mu2eClusterDir::iterate($dir, \&iterateCallBack, $sw, $dsttop);

    if(!$dryrun) {
        my @subdirs = grep { !/^\./ } Mu2eClusterDir::getDirEntries($dir);
        foreach my $d (@subdirs) {
            rmdir $dir.'/'.$d; # OK to fail here
        }
        rmdir $dir; # OK to fail here
    }
}

print "Total time spend talking to SAMWEB server is $totalServerTime seconds\n";
print "Summary: ", join(', ', (map { " $errorCodes{$_}: $jobStats{$_}" } sort keys %jobStats )), "\n";
print "WARNING: can not check for global duplicates with --nosam\n" if $nosam;
print "WARNING: can not check for duplicates with --dry-run\n" if $dryrun;

exit 0;

#================================================================
